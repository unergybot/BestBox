"""
Prometheus metrics definitions for BestBox observability.

This module defines all metrics tracked by the Agent API for monitoring
system performance, user behavior, and agent quality.

Import and use these counters/histograms in your agent code.
"""

from prometheus_client import Counter, Histogram, Gauge

# ==========================================================
# Agent Request Tracking
# ==========================================================

agent_requests = Counter(
    'agent_requests_total',
    'Total agent requests received',
    ['agent_type', 'user_id']
)

# ==========================================================
# Latency Tracking (with SLA-aligned buckets)
# ==========================================================

agent_latency = Histogram(
    'agent_latency_seconds',
    'Agent response latency in seconds',
    ['agent_type'],
    buckets=[0.5, 1.0, 2.0, 5.0, 10.0, 30.0, 60.0, 120.0]  # Aligned with SLA targets
)

# ==========================================================
# LLM Token Generation Tracking
# ==========================================================

llm_tokens_generated = Counter(
    'llm_tokens_total',
    'Total tokens generated by LLM',
    ['model']
)

# ==========================================================
# Tool Execution Tracking
# ==========================================================

tool_execution_success = Counter(
    'tool_executions_total',
    'Tool execution results',
    ['tool_name', 'status']  # status: success | error
)

# ==========================================================
# User Feedback Tracking
# ==========================================================

user_satisfaction = Counter(
    'user_feedback_total',
    'User thumbs up/down feedback',
    ['rating']  # rating: positive | negative
)

# ==========================================================
# Active Session Tracking
# ==========================================================

active_sessions = Gauge(
    'active_sessions',
    'Currently active user sessions'
)

# ==========================================================
# RAG-Specific Metrics
# ==========================================================

rag_retrieval_latency = Histogram(
    'rag_retrieval_seconds',
    'Time to retrieve documents from Qdrant',
    buckets=[0.01, 0.05, 0.1, 0.2, 0.5, 1.0]
)

rag_relevance_score = Histogram(
    'rag_relevance_score',
    'Reranker confidence scores for retrieved documents',
    buckets=[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
)

# ==========================================================
# Router Performance Metrics
# ==========================================================

router_confidence = Histogram(
    'router_confidence_score',
    'Router classification confidence',
    buckets=[0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 1.0]
)

# ==========================================================
# Usage Example
# ==========================================================

"""
Example usage in agent_api.py:

from observability import (
    agent_requests,
    agent_latency,
    llm_tokens_generated,
    tool_execution_success,
    active_sessions
)

@app.post("/chat")
async def chat(request: ChatRequest):
    start_time = time.time()

    # Track request
    agent_requests.labels(
        agent_type="router",
        user_id=request.user_id
    ).inc()

    # Track active sessions
    active_sessions.inc()

    try:
        result = await run_agent(request.message)

        # Track latency
        agent_latency.labels(
            agent_type=result['agent_used']
        ).observe(time.time() - start_time)

        return result
    finally:
        active_sessions.dec()
"""
